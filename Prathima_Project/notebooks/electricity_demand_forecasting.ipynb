{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ireland Electricity Demand Forecasting\n",
    "## Hybrid Interpretable Machine Learning Model\n",
    "\n",
    "**Author:** Prathima Project  \n",
    "**Data Source:** Open Power System Data (OPSD)  \n",
    "\n",
    "---\n",
    "\n",
    "### Research Objectives\n",
    "1. Develop a hybrid ML model combining XGBoost and LSTM\n",
    "2. Implement SHAP-based explainability\n",
    "3. Evaluate robustness under extreme demand conditions\n",
    "4. Create a reproducible benchmark using open data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and Imports\n",
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading\n",
    "\n",
    "We use the Open Power System Data (OPSD) which provides transparent, reproducible electricity data for Ireland."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.config import DATA_DIR, PLOTS_DIR, RESULTS_DIR\n",
    "from src.data_loader import load_and_prepare_data\n",
    "\n",
    "# Load data (downloads if not present)\n",
    "df = load_and_prepare_data(force_download=False)\n",
    "\n",
    "print(f\"\\nData Shape: {df.shape}\")\n",
    "print(f\"Date Range: {df.index.min()} to {df.index.max()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Statistics\n",
    "print(\"Demand Statistics:\")\n",
    "df['demand'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time Series Overview\n",
    "fig, ax = plt.subplots(figsize=(16, 6))\n",
    "ax.plot(df.index, df['demand'], linewidth=0.5, alpha=0.7)\n",
    "ax.set_title('Ireland Electricity Demand Over Time', fontsize=14)\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Demand (MW)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily Pattern\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Hourly pattern\n",
    "hourly_mean = df.groupby(df.index.hour)['demand'].mean()\n",
    "hourly_std = df.groupby(df.index.hour)['demand'].std()\n",
    "\n",
    "axes[0].fill_between(hourly_mean.index, hourly_mean - hourly_std, \n",
    "                      hourly_mean + hourly_std, alpha=0.3)\n",
    "axes[0].plot(hourly_mean.index, hourly_mean, linewidth=2, marker='o')\n",
    "axes[0].set_title('Average Daily Demand Pattern', fontsize=12)\n",
    "axes[0].set_xlabel('Hour of Day')\n",
    "axes[0].set_ylabel('Demand (MW)')\n",
    "axes[0].set_xticks(range(0, 24, 2))\n",
    "\n",
    "# Weekly pattern\n",
    "days = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
    "daily_mean = df.groupby(df.index.dayofweek)['demand'].mean()\n",
    "daily_std = df.groupby(df.index.dayofweek)['demand'].std()\n",
    "\n",
    "axes[1].bar(range(7), daily_mean, yerr=daily_std, capsize=3, alpha=0.7)\n",
    "axes[1].set_title('Average Weekly Demand Pattern', fontsize=12)\n",
    "axes[1].set_xlabel('Day of Week')\n",
    "axes[1].set_ylabel('Demand (MW)')\n",
    "axes[1].set_xticks(range(7))\n",
    "axes[1].set_xticklabels(days)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap: Hour vs Day of Week\n",
    "pivot = df.pivot_table(values='demand', \n",
    "                        index=df.index.hour, \n",
    "                        columns=df.index.dayofweek, \n",
    "                        aggfunc='mean')\n",
    "pivot.columns = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(pivot, cmap='YlOrRd', annot=True, fmt='.0f', cbar_kws={'label': 'MW'})\n",
    "plt.title('Average Hourly Demand by Day of Week', fontsize=14)\n",
    "plt.xlabel('Day of Week')\n",
    "plt.ylabel('Hour of Day')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.feature_engineering import engineer_features, get_feature_columns\n",
    "\n",
    "# Apply feature engineering\n",
    "df_featured = engineer_features(df)\n",
    "\n",
    "print(f\"\\nOriginal columns: {len(df.columns)}\")\n",
    "print(f\"After feature engineering: {len(df_featured.columns)}\")\n",
    "print(f\"\\nNew features created: {len(df_featured.columns) - len(df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View feature columns\n",
    "feature_cols = get_feature_columns(df_featured)\n",
    "print(f\"Feature columns ({len(feature_cols)}):\")\n",
    "for i, col in enumerate(feature_cols, 1):\n",
    "    print(f\"  {i}. {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.preprocessing import split_data\n",
    "\n",
    "# Split data into train, validation, test\n",
    "train_df, val_df, test_df = split_data(df_featured)\n",
    "\n",
    "# Prepare X and y\n",
    "X_train = train_df[feature_cols]\n",
    "y_train = train_df['demand'].values\n",
    "\n",
    "X_val = val_df[feature_cols]\n",
    "y_val = val_df['demand'].values\n",
    "\n",
    "X_test = test_df[feature_cols]\n",
    "y_test = test_df['demand'].values\n",
    "\n",
    "print(f\"\\nTraining set: {X_train.shape}\")\n",
    "print(f\"Validation set: {X_val.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import RandomForestModel, XGBoostModel, HybridModel\n",
    "\n",
    "models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest\n",
    "print(\"Training Random Forest...\")\n",
    "rf_model = RandomForestModel()\n",
    "rf_model.fit(X_train, y_train)\n",
    "models['Random Forest'] = rf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train XGBoost\n",
    "print(\"Training XGBoost...\")\n",
    "xgb_model = XGBoostModel()\n",
    "xgb_model.fit(X_train, y_train, X_val, y_val)\n",
    "models['XGBoost'] = xgb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Hybrid Model (XGBoost + LSTM)\n",
    "print(\"Training Hybrid Model...\")\n",
    "try:\n",
    "    hybrid_model = HybridModel()\n",
    "    hybrid_model.fit(X_train, y_train, X_val, y_val, feature_cols)\n",
    "    models['Hybrid'] = hybrid_model\n",
    "except Exception as e:\n",
    "    print(f\"Hybrid model training failed: {e}\")\n",
    "    print(\"Continuing with tree-based models...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.evaluation import evaluate_models, calculate_metrics\n",
    "\n",
    "# Evaluate all models\n",
    "results_df = evaluate_models(models, X_test, y_test)\n",
    "print(\"\\nModel Comparison:\")\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model comparison\n",
    "from src.visualization import plot_model_comparison\n",
    "\n",
    "plot_model_comparison(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model predictions\n",
    "best_model_name = results_df.iloc[0]['model']\n",
    "best_model = models[best_model_name]\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Plot predictions\n",
    "from src.visualization import plot_predictions\n",
    "\n",
    "plot_predictions(y_test, y_pred, dates=test_df.index, model_name=best_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance from XGBoost\n",
    "importance = xgb_model.get_feature_importance(top_n=20)\n",
    "print(\"Top 20 Important Features:\")\n",
    "importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.visualization import plot_feature_importance\n",
    "\n",
    "plot_feature_importance(importance, title='XGBoost Feature Importance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. SHAP Explainability Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.explainability import compute_shap_values, plot_shap_summary, plot_shap_bar\n",
    "\n",
    "# Compute SHAP values\n",
    "shap_values, explainer, X_sample = compute_shap_values(xgb_model, X_test, feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP Summary Plot\n",
    "plot_shap_summary(shap_values, X_sample, feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP Bar Plot\n",
    "shap_importance = plot_shap_bar(shap_values, feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP Dependence Plot for top features\n",
    "from src.explainability import plot_shap_dependence\n",
    "\n",
    "top_feature = shap_importance.iloc[-1]['feature']  # Most important\n",
    "plot_shap_dependence(shap_values, X_sample, top_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Extreme Event Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.evaluation import evaluate_extreme_events\n",
    "\n",
    "# Analyze performance during extreme events\n",
    "extreme_results = evaluate_extreme_events(best_model, X_test, y_test, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare performance across conditions\n",
    "conditions = ['normal_conditions', 'high_demand', 'low_demand']\n",
    "metrics_comparison = []\n",
    "\n",
    "for condition in conditions:\n",
    "    if condition in extreme_results:\n",
    "        m = extreme_results[condition]\n",
    "        metrics_comparison.append({\n",
    "            'Condition': condition.replace('_', ' ').title(),\n",
    "            'MAE': m['MAE'],\n",
    "            'RMSE': m['RMSE'],\n",
    "            'MAPE': m['MAPE']\n",
    "        })\n",
    "\n",
    "pd.DataFrame(metrics_comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Hourly Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.evaluation import evaluate_by_time_period\n",
    "\n",
    "# Analyze by time period\n",
    "time_analysis = evaluate_by_time_period(best_model, X_test, y_test, test_df)\n",
    "\n",
    "if 'hourly' in time_analysis:\n",
    "    print(\"Hourly Performance:\")\n",
    "    display(time_analysis['hourly'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot hourly performance\n",
    "from src.visualization import plot_hourly_performance\n",
    "\n",
    "if 'hourly' in time_analysis:\n",
    "    plot_hourly_performance(time_analysis['hourly'], metric='MAPE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Conclusions\n",
    "\n",
    "### Key Findings:\n",
    "\n",
    "1. **Model Performance**: The hybrid/XGBoost model achieves competitive accuracy for hourly forecasting\n",
    "\n",
    "2. **Important Features**: \n",
    "   - Lag features (previous hour, previous day) are most important\n",
    "   - Temporal features (hour, day of week) capture demand patterns\n",
    "   - Rolling statistics help smooth predictions\n",
    "\n",
    "3. **Explainability**: SHAP analysis reveals:\n",
    "   - Clear impact of time-of-day on predictions\n",
    "   - Weekend/weekday effects on demand\n",
    "   - Seasonal variations in importance\n",
    "\n",
    "4. **Robustness**: Model performance varies under extreme conditions\n",
    "\n",
    "### Contributions:\n",
    "- Reproducible benchmark using open OPSD data\n",
    "- Hybrid architecture combining XGBoost and LSTM\n",
    "- SHAP-based interpretability for transparency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Summary\n",
    "print(\"=\"*60)\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nBest Model: {best_model_name}\")\n",
    "print(f\"Test RMSE: {results_df.iloc[0]['RMSE']:.2f} MW\")\n",
    "print(f\"Test MAPE: {results_df.iloc[0]['MAPE']:.2f}%\")\n",
    "print(f\"Test RÂ²: {results_df.iloc[0]['R2']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
